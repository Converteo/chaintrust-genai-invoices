{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76530e8b-0341-4ebf-bf6b-8cfcf650d56a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (18.1.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "MR3bvBE7VcDD",
   "metadata": {
    "id": "MR3bvBE7VcDD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import google.cloud.bigquery as bigquery\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "au6FQADGlGdi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "au6FQADGlGdi",
    "outputId": "eeb16f55-86b0-4ccd-96cc-8c831a280519",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to your service account key file - INPUT KEY HERE\n",
    "key_path = \"credentials/c-synomia-givaudan-140eba0163dc.json\"\n",
    "\n",
    "# Authenticate with the service account key\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "project_id = 'c-synomia-givaudan'\n",
    "\n",
    "# Initialize a BigQuery client with the credentials\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19YX1k1FRQj7",
   "metadata": {
    "id": "19YX1k1FRQj7"
   },
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41T76nA6aR9d",
   "metadata": {
    "id": "41T76nA6aR9d"
   },
   "source": [
    "Project IDs to keep :\n",
    "- Codification 1 : 485, 466, 489, 503\n",
    "- Codification 2 : 487\n",
    "- Codification 3 : 493"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vGQXhQZqdwCx",
   "metadata": {
    "id": "vGQXhQZqdwCx"
   },
   "source": [
    "## 1. DATA LOADING AND UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5jBWUmgeMxk",
   "metadata": {
    "id": "e5jBWUmgeMxk"
   },
   "source": [
    "### Final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "HZ9GtbEsV5Gf",
   "metadata": {
    "id": "HZ9GtbEsV5Gf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectId</th>\n",
       "      <th>verbatim_content</th>\n",
       "      <th>theme_name</th>\n",
       "      <th>fragrance</th>\n",
       "      <th>emotion</th>\n",
       "      <th>keyword_value_original</th>\n",
       "      <th>keyword_value_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489</td>\n",
       "      <td>Feeling like I am wearing something so elegant...</td>\n",
       "      <td>01.Crush</td>\n",
       "      <td>B10</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489</td>\n",
       "      <td>Feeling like I am wearing something so elegant...</td>\n",
       "      <td>01.Crush</td>\n",
       "      <td>BZA</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489</td>\n",
       "      <td>Feeling like I am wearing something so elegant...</td>\n",
       "      <td>05.Uniqueness</td>\n",
       "      <td>B10</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>party</td>\n",
       "      <td>party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>489</td>\n",
       "      <td>Feeling like I am wearing something so elegant...</td>\n",
       "      <td>06.Quality</td>\n",
       "      <td>B10</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>elegant</td>\n",
       "      <td>elegante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489</td>\n",
       "      <td>Feeling like I am wearing something so elegant...</td>\n",
       "      <td>06.Quality</td>\n",
       "      <td>BZA</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>elegant</td>\n",
       "      <td>elegante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProjectId                                   verbatim_content  \\\n",
       "0        489  Feeling like I am wearing something so elegant...   \n",
       "1        489  Feeling like I am wearing something so elegant...   \n",
       "2        489  Feeling like I am wearing something so elegant...   \n",
       "3        489  Feeling like I am wearing something so elegant...   \n",
       "4        489  Feeling like I am wearing something so elegant...   \n",
       "\n",
       "      theme_name fragrance   emotion keyword_value_original  \\\n",
       "0       01.Crush       B10  POSITIVE                   love   \n",
       "1       01.Crush       BZA  POSITIVE                   love   \n",
       "2  05.Uniqueness       B10  POSITIVE                  party   \n",
       "3     06.Quality       B10  POSITIVE                elegant   \n",
       "4     06.Quality       BZA  POSITIVE                elegant   \n",
       "\n",
       "  keyword_value_cleaned  \n",
       "0                  love  \n",
       "1                  love  \n",
       "2                 party  \n",
       "3              elegante  \n",
       "4              elegante  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "dataset_id = 'c-synomia-givaudan.givaudan_project_tables_processed'\n",
    "table_id = 'final_table_cleaned'\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `{}`.`{}`\n",
    "WHERE ProjectId IN (485, 466, 489, 503)\"\"\".format(dataset_id, table_id)\n",
    "\n",
    "df_verbatim = client.query(query).to_dataframe()\n",
    "# List of columns to drop\n",
    "columns_to_drop = [\n",
    "    \"VerbatimId\",\n",
    "    \"KeywordId\",\n",
    "    \"Codif1\",\n",
    "    \"theme_id\",\n",
    "    \"avis\",\n",
    "    \"age\",\n",
    "    \"classement\",\n",
    "    \"theme_order\"\n",
    "]\n",
    "\n",
    "# Drop the specified columns\n",
    "df_verbatim = df_verbatim.drop(columns=columns_to_drop)\n",
    "df_verbatim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Oa6sse-VMm3X",
   "metadata": {
    "id": "Oa6sse-VMm3X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Group by 'verbatim_content' and check if duplicates exist across different ProjectIds\n",
    "content_project_counts = df_verbatim.groupby('verbatim_content')['ProjectId'].nunique()\n",
    "\n",
    "# Step 2: Identify 'verbatim_content' duplicated across different ProjectIds\n",
    "cross_project_duplicates = content_project_counts[content_project_counts > 1].index\n",
    "\n",
    "# Step 3: Filter rows where verbatim_content is in the duplicated list and keep ProjectId == 503\n",
    "keep_503 = df_verbatim[(df_verbatim['verbatim_content'].isin(cross_project_duplicates)) & (df_verbatim['ProjectId'] == 503)]\n",
    "\n",
    "# Step 4: Remove all cross-project duplicates and add back rows where ProjectId == 503\n",
    "filtered_df = pd.concat([\n",
    "    df_verbatim[~df_verbatim['verbatim_content'].isin(cross_project_duplicates)],  # Keep non-duplicated rows\n",
    "    keep_503  # Add rows where ProjectId == 503 for cross-project duplicates\n",
    "])\n",
    "\n",
    "# Optional: Reset index for cleaner DataFrame\n",
    "df_verbatim = filtered_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "QKT_1wD-RUbH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKT_1wD-RUbH",
    "outputId": "72328e97-7e2b-4824-f5e9-8d2d2a050033",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_verbatim.theme_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "heuaohmqHGKi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "heuaohmqHGKi",
    "outputId": "bb9a07a4-fa6f-4f0b-f0c8-d9b410ba64b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess theme_name to remove numbers followed by a dot\n",
    "df_verbatim.theme_name = df_verbatim.theme_name.str.replace(r'\\d+\\.', '', regex=True)\n",
    "\n",
    "# Initialize the JSON structure\n",
    "verbatim_json = {}\n",
    "\n",
    "# Group the DataFrame by 'verbatim_content'\n",
    "grouped = df_verbatim.groupby('verbatim_content')\n",
    "\n",
    "# Iterate through each group\n",
    "for verbatim_content, group in grouped:\n",
    "    emotion = group['emotion'].iloc[0]\n",
    "\n",
    "    # Check for inconsistent emotions\n",
    "    if group['emotion'].nunique() > 1:\n",
    "        print(f\"Emotion not consistent for verbatim_content: {verbatim_content}\")\n",
    "\n",
    "    # Check for None in keyword_value_original or theme_name\n",
    "    if group['keyword_value_original'].isnull().any() or group['theme_name'].isnull().any():\n",
    "        keyword_theme_mapping = {}\n",
    "    else:\n",
    "        # Create the keyword/theme mapping\n",
    "        keyword_theme_mapping = dict(zip(group['keyword_value_original'], group['theme_name']))\n",
    "\n",
    "    # Populate the JSON structure\n",
    "    verbatim_json[verbatim_content.strip()] = {\n",
    "        \"emotion\": emotion,\n",
    "        \"keyword / theme\": keyword_theme_mapping,\n",
    "    }\n",
    "\n",
    "# Write the JSON structure to a file\n",
    "with open('verbatim_ground_truth.json', 'w') as f:\n",
    "    json.dump(verbatim_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "P4anbqfoK4LN",
   "metadata": {
    "id": "P4anbqfoK4LN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_set = {k : v for i, (k, v) in enumerate(verbatim_json.items()) if i < 500}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YvgothgDxE60",
   "metadata": {
    "id": "YvgothgDxE60"
   },
   "source": [
    "# Finetuning Part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pZQGu0xkOPnW",
   "metadata": {
    "id": "pZQGu0xkOPnW"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ULLJEhl3ztcQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULLJEhl3ztcQ",
    "outputId": "e0a3b1d9-4586-48a6-a9b7-bce156bf5870",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1819"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_validation_data = {k : v for i, (k, v) in enumerate(verbatim_json.items()) if i>= 500}\n",
    "len(training_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "r8NWSKKr0mL4",
   "metadata": {
    "id": "r8NWSKKr0mL4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_content_finetuning(verbatim, output_json):\n",
    "    prompt_user = \"\"\"Analyze the provided text and extract the overall emotion and key themes associated with the main keywords. Output the analysis as a JSON object. The JSON object should have two keys: \"emotion\" and \"keyword / theme\".\n",
    "\n",
    "    The \"emotion\" value should be one of the following: \"POSITIVE\", \"NEGATIVE\", or \"NEUTRAL\".\n",
    "\n",
    "    The \"keyword / theme\" value should be a JSON object where each key is a keyword extracted from the input text and each value is the associated theme for that keyword.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "    Input: Ooh! I love this! I think it would be my favorite fragrance. It's sweet, like roses, but it has some spice in there, like cinnamon. It's well-balanced, and not too strong.\n",
    "    Output: {\"emotion\": \"POSITIVE\", \"keyword / theme\": {\"sweet\": \"Sweet\", \"spice\": \"Spicy/Woody/Smoky\", \"strong\": \"Intensity\", \"rose\": \"Ingredient ID - Flower\", \"cinnamon\": \"Ingredient ID - Spicy/Woody/Aro\"}}\n",
    "\n",
    "    Input: Oh wow that is really strong. I don't like this one , it smells to much of chemicals in my opinion. It is too overpowering and I feel like if I wore this that other people would make fun of me or not want to be around me.\n",
    "    Output: {\"emotion\": \"NEGATIVE\", \"keyword / theme\": {\"wow\": \"Crush\", \"fun\": \"Feel Good\", \"strong\": \"Intensity\", \"chemical\": \"Functional/Chemical\"}}\n",
    "\n",
    "    Input: A old lady, that's in her 60s. I think of those old picture frames my grandma had in her kitchen and they looked like they were just about to fade.\n",
    "    Output: {\"emotion\": \"NEUTRAL\", \"keyword / theme\": {\"lady\": \"Feminine\", \"old\": \"Old-fashioned\", \"old lady\": \"Old-fashioned\", \"grandma\": \"Old-fashioned\"}}\n",
    "\n",
    "    Input: A perfect sweet like candy, a tropical tang with melons and bright rich golden orange melons.\n",
    "    Output: {\"emotion\": \"POSITIVE\", \"keyword / theme\": {\"bright\": \"Feel Good\", \"sweet\": \"Sweet\", \"melon\": \"Ingredient ID - Fruit\", \"candy\": \"Ingredient ID - Food\"}}\n",
    "\n",
    "    Input:\"\"\"+verbatim+\"\"\"\n",
    "    Output:\"\"\"\n",
    "    return {'contents': [\n",
    "              {'role': 'user',\n",
    "               'parts': [{'text': prompt_user}]\n",
    "               },\n",
    "              {'role': 'model',\n",
    "               'parts': [{'text': json.dumps(output_json)}]\n",
    "               }\n",
    "              ]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "r5ydDe0u3Xr1",
   "metadata": {
    "id": "r5ydDe0u3Xr1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert dictionary items to a list of tuples\n",
    "data_items = list(training_validation_data.items())\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_items, test_items = train_test_split(data_items, test_size=0.12, random_state=42)\n",
    "\n",
    "# Convert the lists of tuples back to dictionaries\n",
    "train_dict = dict(train_items)\n",
    "test_dict = dict(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "S7jhmMsO34OD",
   "metadata": {
    "id": "S7jhmMsO34OD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_jsonl_file(data_dict,output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        for verbatim, json_answer in data_dict.items():\n",
    "            json_data = build_content_finetuning(verbatim, json_answer)\n",
    "            json.dump(json_data, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "create_jsonl_file(train_dict,'finetuning data/train_data_finetuning_synomia2.jsonl')\n",
    "create_jsonl_file(test_dict,'finetuning data/validation_data_finetuning_synomia2.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xsmq30zS6xcH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xsmq30zS6xcH",
    "outputId": "07596058-a00a-4221-8846-d24ca48d9edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File train_data_finetuning_synomia2.jsonl uploaded to the bucket finetuning_data/train_data_finetuning_synomia2.jsonl.\n",
      "File validation_data_finetuning_synomia2.jsonl uploaded to the bucket finetuning_data/validation_data_finetuning_synomia2.jsonl.\n"
     ]
    }
   ],
   "source": [
    "# Depot dans GCS\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "location = \"us-central1\"\n",
    "PROJECT_ID = \"c-test-gen-ai-synomia\"\n",
    "bucket_name = \"projet_givaudan\"\n",
    "folder_output_name = 'finetuning_data'\n",
    "\n",
    "def upload_blob(bucket_name, file_path):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    destination_blob_name = os.path.join(folder_output_name, file_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(file_path)\n",
    "\n",
    "    print(\n",
    "        f\"File {file_name} uploaded to the bucket {destination_blob_name}.\"\n",
    "    )\n",
    "\n",
    "upload_blob(bucket_name, 'train_data_finetuning_synomia2.jsonl')\n",
    "upload_blob(bucket_name, 'validation_data_finetuning_synomia2.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x3DdbAYaOHJX",
   "metadata": {
    "id": "x3DdbAYaOHJX"
   },
   "source": [
    "## Finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LagYkQCH8pH4",
   "metadata": {
    "id": "LagYkQCH8pH4"
   },
   "outputs": [],
   "source": [
    "def get_model_finetuned(model_name,training_file,validation_file, display_name):\n",
    "    sft_tuning_job = sft.train(\n",
    "        source_model=model_name,\n",
    "        train_dataset=f'gs://projet_givaudan/finetuning_data/{training_file}',\n",
    "        validation_dataset=f\"gs://projet_givaudan/finetuning_data/{validation_file}\",\n",
    "        epochs=4,\n",
    "        adapter_size=4,\n",
    "        learning_rate_multiplier=1.0,\n",
    "        tuned_model_display_name=display_name,\n",
    "    )\n",
    "\n",
    "    # Polling for job completion\n",
    "    while not sft_tuning_job.has_ended:\n",
    "        time.sleep(60)\n",
    "        sft_tuning_job.refresh()\n",
    "\n",
    "    print(sft_tuning_job.tuned_model_name)\n",
    "    print(sft_tuning_job.tuned_model_endpoint_name)\n",
    "    print(sft_tuning_job.experiment)\n",
    "\n",
    "\n",
    "tuning_job_id = \"2554971831303929856\"\n",
    "\n",
    "def cancel_job(tuning_id):\n",
    "    job = sft.SupervisedTuningJob(\n",
    "        f\"projects/{PROJECT_ID}/locations/{location}/tuningJobs/{tuning_job_id}\"\n",
    "    )\n",
    "    job.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YQEHhEvl-rEI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "YQEHhEvl-rEI",
    "outputId": "4c457013-79aa-4872-d5e1-b8e13ae66dca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vertexai.tuning._tuning:Creating SupervisedTuningJob\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/c-test-gen-ai-synomia/locations/us-central1/tuningJobs?%24alt=json%3Benum-encoding%3Dint: Base model gemini-2.0-flash-exp is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-edc0d948c593>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"tuned_gemini_2_flash\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m get_model_finetuned(model_name,\n\u001b[0m\u001b[1;32m      8\u001b[0m                         \u001b[0mtraining_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \u001b[0mvalidation_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-0c84089e80ee>\u001b[0m in \u001b[0;36mget_model_finetuned\u001b[0;34m(model_name, training_file, validation_file, display_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model_finetuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     sft_tuning_job = sft.train(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0msource_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'gs://projet_givaudan/finetuning_data/{training_file}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/tuning/_supervised_tuning.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(source_model, train_dataset, validation_dataset, tuned_model_display_name, epochs, learning_rate_multiplier, adapter_size, labels)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     supervised_tuning_job = (\n\u001b[0;32m---> 92\u001b[0;31m         SupervisedTuningJob._create(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mbase_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mtuning_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupervised_tuning_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/tuning/_tuning.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, base_model, tuning_spec, tuned_model_display_name, description, labels, project, location, credentials)\u001b[0m\n\u001b[1;32m    217\u001b[0m         )\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         created_gca_tuning_job = tuning_job.api_client.create_tuning_job(\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mtuning_job\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgca_tuning_job\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform_v1beta1/services/gen_ai_tuning_service/client.py\u001b[0m in \u001b[0;36mcreate_tuning_job\u001b[0;34m(self, request, parent, tuning_job, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    936\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform_v1beta1/services/gen_ai_tuning_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2762\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2763\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2764\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2766\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/c-test-gen-ai-synomia/locations/us-central1/tuningJobs?%24alt=json%3Benum-encoding%3Dint: Base model gemini-2.0-flash-exp is not supported."
     ]
    }
   ],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "model_name = \"gemini-1.5-flash-002\"\n",
    "training_file = \"train_data_finetuning_synomia2.jsonl\"\n",
    "validation_file = \"validation_data_finetuning_synomia2.jsonl\"\n",
    "display_name = \"tuned_gemini_1_5_flash\"\n",
    "\n",
    "get_model_finetuned(model_name,\n",
    "                        training_file,\n",
    "                        validation_file,\n",
    "                        display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aGv6o0EwoZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 57
    },
    "id": "d6aGv6o0EwoZ",
    "outputId": "85717be6-24fe-4008-8ffd-0bf081921f1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-8a25a14d-83fa-4752-9804-3cdfee8f90a4\" href=\"#view-view-vertex-resource-8a25a14d-83fa-4752-9804-3cdfee8f90a4\">\n",
       "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
       "          <span>View Tuning Job</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-8a25a14d-83fa-4752-9804-3cdfee8f90a4');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/8802810179260252160?project=120594540559');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/8802810179260252160?project=120594540559', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, HarmCategory, HarmBlockThreshold, SafetySetting\n",
    "from vertexai.tuning import sft\n",
    "\n",
    "sft_tuning_job_gemini_flash = sft.SupervisedTuningJob('projects/120594540559/locations/us-central1/tuningJobs/8802810179260252160')\n",
    "model = GenerativeModel(sft_tuning_job_gemini_flash.tuned_model_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "m4eyQqoUfG8v",
    "7W_lLhCnOZLf",
    "YvgothgDxE60",
    "W6pcALI7N-Rg"
   ],
   "name": "4_G_Finetuning_Gemini",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-17.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-17:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
